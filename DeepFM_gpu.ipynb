{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepFM_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d8TIM4eRKsh",
        "colab_type": "code",
        "outputId": "b4bf8770-4416-48ed-bb59-a138f969be77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb7mTCaIRxtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZsX5hVnRxwh",
        "colab_type": "code",
        "outputId": "778c8afa-b234-4e5a-8a9d-05f9de26bf75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gpu()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-2237.734>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nKCCBTwKnpa",
        "colab_type": "code",
        "outputId": "22627b75-8ce7-4d10-f91f-07ccffa5c860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "!pip install deepctr\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from deepctr.models import DeepFM\n",
        "from deepctr.inputs import SparseFeat,get_feature_names\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/\")\n",
        "time1=time.time()\n",
        "#数据加载\n",
        "data = pd.read_csv(\"movielens_sample.txt\")\n",
        "sparse_features = [\"movie_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
        "target = ['rating']\n",
        "\n",
        "# 对特征标签进行编码\n",
        "for feature in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    data[feature] = lbe.fit_transform(data[feature])\n",
        "# 计算每个特征中的 不同特征值的个数\n",
        "fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique()) for feature in sparse_features]\n",
        "print(fixlen_feature_columns)\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "# 将数据集切分成训练集和测试集\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "train_model_input = {name:train[name].values for name in feature_names}\n",
        "test_model_input = {name:test[name].values for name in feature_names}\n",
        "\n",
        "# 使用DeepFM进行训练\n",
        "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
        "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=1, verbose=True, validation_split=0.2, )\n",
        "# 使用DeepFM进行预测\n",
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "# 输出RMSE或MSE\n",
        "mse = round(mean_squared_error(test[target].values, pred_ans), 4)\n",
        "rmse = mse ** 0.5\n",
        "print(\"test RMSE\", rmse)\n",
        "time2=time.time()\n",
        "print(\"时间为\"+str(time2-time1))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepctr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/8e/03d45ded03d594212003801e2b4af0927b66575741fd6df72a07fb6affd3/deepctr-0.7.2-py3-none-any.whl (79kB)\n",
            "\r\u001b[K     |████                            | 10kB 29.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from deepctr) (2.22.0)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (from deepctr) (2.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->deepctr) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->deepctr) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->deepctr) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->deepctr) (3.0.4)\n",
            "Requirement already satisfied: numpy>=1.7 in /tensorflow-2.1.0/python3.6 (from h5py->deepctr) (1.18.1)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from h5py->deepctr) (1.14.0)\n",
            "Installing collected packages: deepctr\n",
            "Successfully installed deepctr-0.7.2\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[SparseFeat(name='movie_id', vocabulary_size=187, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='movie_id', group_name='default_group'), SparseFeat(name='user_id', vocabulary_size=193, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='user_id', group_name='default_group'), SparseFeat(name='gender', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='gender', group_name='default_group'), SparseFeat(name='age', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='age', group_name='default_group'), SparseFeat(name='occupation', vocabulary_size=20, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='occupation', group_name='default_group'), SparseFeat(name='zip', vocabulary_size=188, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='zip', group_name='default_group')]\n",
            "Train on 128 samples, validate on 32 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r128/128 [==============================] - 2s 14ms/sample - loss: 13.7901 - mse: 13.7901 - val_loss: 15.3464 - val_mse: 15.3464\n",
            "test RMSE 3.7598404221455994\n",
            "时间为3.647986888885498\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}