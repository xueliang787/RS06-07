{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking1 在实际工作中，FM和MF哪个应用的更多，为什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FM和MF的区别\n",
    "    FM矩阵将User和Item都进行了one-hot编码作为特征，使得特征维度非常巨大且稀疏\n",
    "    矩阵分解MF是FM的特例，即特征只有User ID 和Item ID的FM模型\n",
    "    矩阵分解MF只适用于评分预测，进行简单的特征计算，无法利用其他特征 \n",
    "    FM引入了更多辅助信息（Side information）作为特征\n",
    "    FM在计算二阶特征组合系数的时候，使用了MF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 根据FM和MF的区别，不难看出，在实际工作中FM应用的更多，MF的局限性太强。\n",
    "    FM可以可以用来解决多个特征的评分补全问题，也可以用在解决回归问题，也可以通过SIGMOD函数解决二分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking2 FFM与FM有哪些区别？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FFM在FM的基础上，通过引入field的概念，FFM把相同性质的特征归于同一个field。FM是FFM的特例\n",
    "    FM每个特征有唯一的一个隐向量表示，这个隐向量被用来学习与其他任何特征之间的影响。\n",
    "    FFM每个特征会有几个不同的隐向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking3 DeepFM相比于FM解决了哪些问题，原理是怎样的\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解决了高阶特征组合的问题\n",
    "    FM可以做特征组合，但是计算量大，一般只考虑2阶特征组合。\n",
    "    既考虑低阶特征组合和高阶特征组合就需要使用DeepFM， DeepFM=FM+DNN。\n",
    "    在低阶和高阶特征组合上更接近真实世界，因此效果也更好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 原理\n",
    "     DeepFM=FM+DNN\n",
    "    提取低阶(low order)特征 => 因子分解机FM 既可以做1阶特征建模，也可以做2阶特征建模\n",
    "    提取高阶(high order)特征 => 神经网络DNN\n",
    "    FM模型和Deep模型中的子网络权重共享，也就是对于同一个特征，向量Vi是相同的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking4 假设一个小说网站，有N部小说，每部小说都有摘要描述。如何针对该网站制定基于内容的推荐系统，即用户看了某部小说后，推荐其他相关的小说。原理和步骤是怎样的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 步骤\n",
    "        Step1，对酒店描述（Desc）进行特征提取\n",
    "            N-Gram，提取N个连续字的集合，作为特征\n",
    "            TF-IDF，按照(min_df, max_df)提取关键词，并生成TFIDF矩阵\n",
    "        Step2，计算酒店之间的相似度矩阵\n",
    "               余弦相似度\n",
    "        Step3，对于指定的酒店，选择相似度最大的Top-K个酒店进行输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 原理\n",
    "    \n",
    "     其中，余弦相似度的计算原理是通过测量两个向量的夹角的余弦值来度量它们之间的相似性。\n",
    "    判断两个向量⼤致方向是否相同，方向相同时，余弦相似度为1；两个向量夹角为90°时，余弦相似度的值为0，方向完全相反时，余弦相似度的值为-1。\n",
    "    两个向量之间夹角的余弦值为[-1, 1]\n",
    "    \n",
    "    N-Gram 基于一个假设：第n个词出现与前n-1个词相关，而与其他任何词不相关。当一阶特征不够用时，可以用N-Gram做为新的特征。\n",
    "    TF-IDF 抽取文本的重要特征，做成item embedding ，将文档集合转化为tf-idf特征值的矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking5 Word2Vec的应用场景有哪些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 推荐系统中\n",
    "    大V推荐中，大V => 单词，将每一个用户关注大V的顺序 => 文章\n",
    "    商品推荐中，商品 => 单词，用户对商品的行为顺序 => 文章等等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLP中\n",
    "    计算文章中一些词或句子之间的相似度\n",
    "    也可以作为另一个模型的输入\n",
    "    信息检索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action1 使用libfm工具对movielens进行评分预测，采用SGD优化算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### windows下需要安装perl环境，因此安装Strawberry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 首先\n",
    "    使用 \n",
    "    perl triple_format_to_libfm.pl -in ratings.dat -target 2 -delete_column 3 -separator \"::\" \n",
    "    命令，将数据转化为指定格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 其次\n",
    "       使用\n",
    "       libFM -task r -train ratings.dat.libfm -test ratings.dat.libfm -dim '1,1,8' -iter 1000 -method sgd -learn_rate 0.01 -regular '0,0,0.01' -init_stdev  -out movielens_out.txt\n",
    "       命令，对评分预测，使用SGD优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 最终结果如下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![title](picture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 因为设置迭代次数为1000次，实际上迭代大概300次左右就已经收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![title](2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 结果保存在movielens_out文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![title](3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action2 使用DeepFM对movielens进行评分预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DeepFM_gpu.ipynb和DeepFM_gpu_all.ipynb 文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action3 使用Gensim中的Word2Vec对三国演义进行Word Embedding，分析和曹操最相近的词有哪些，曹操+刘备-张飞=?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word2vec.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
